---
# AI Generation - Fixed Version
# Single function per chunk, no duplicates

---
# CHUNK 1/4: Executive Summary Generation
id: generate_executive_summary
variable: executive_summary
code: |
  from docassemble.base.util import log, get_config, define
  log("üìã CHUNK 1/4: Executive Summary Generation - Starting...")
  
  import os
  import json
  import openai
  import httpx
  
  try:
    # Get API key
    api_key = get_config('openai api key')
    if not api_key:
      openai_config = get_config('openai', {})
      api_key = openai_config.get('api_key')
    if not api_key:
      api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
      raise Exception("No OpenAI API key found")
    
    log(f"‚úÖ API key found: {api_key[:10]}...")
    
    # Load prompts
    try:
      from docassemble.base.util import path_and_mimetype
      da_path = path_and_mimetype('ai_prompts.json')[0]
      if da_path and os.path.exists(da_path):
        with open(da_path, 'r') as f:
          config = json.load(f)
        log("‚úÖ AI prompts loaded successfully")
      else:
        raise Exception("AI prompts file not found")
    except Exception as e:
      log(f"‚ùå Error loading AI prompts: {e}")
      raise
    
    # Get prompt config
    prompt_config = config['prompts'].get('executive_summary')
    if not prompt_config:
      raise ValueError("Executive summary prompt not found")
    
    system_prompt = prompt_config.get('system', '')
    user_prompt = prompt_config.get('user_template', '')
    
    # Format user prompt
    try:
      formatted_user_prompt = user_prompt.format(
        formatted_data=formatted_data,
        company_name=user_information.get('company', 'this organization') if defined('user_information') and user_information else 'this organization',
        overall_score=overall_score if defined('overall_score') else 'N/A',
        industry_average=industry_average if defined('industry_average') else 'N/A'
      )
    except KeyError as e:
      log(f"‚ö†Ô∏è Warning: Missing template variable {e}, using raw prompt")
      formatted_user_prompt = user_prompt
    
    # Create OpenAI client
    client = openai.OpenAI(
      api_key=api_key,
      timeout=httpx.Timeout(connect=10.0, write=60.0, read=60.0, pool=30.0),
      max_retries=3
    )
    log("‚úÖ OpenAI client created")
    
    # Make API call
    response = client.chat.completions.create(
      model='gpt-4.1-mini',
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": formatted_user_prompt}
      ],
      max_tokens=1000,
      temperature=0.6
    )
    
    executive_summary = response.choices[0].message.content.strip()
    log(f"‚úÖ Executive summary generated: {len(executive_summary)} chars")
    
  except Exception as e:
    log(f"‚ùå Executive summary generation failed: {e}")
    executive_summary = f"Executive summary generation failed: {str(e)}"

---
# CHUNK 2/4: Contradictions & Insights Generation  
id: generate_contradictions_insights
variable: contradictions_insights
code: |
  from docassemble.base.util import log, get_config, define
  log("üìã CHUNK 2/4: Contradictions & Insights Generation - Starting...")
  
  import os
  import json
  import openai
  import httpx
  
  try:
    # Get API key
    api_key = get_config('openai api key')
    if not api_key:
      openai_config = get_config('openai', {})
      api_key = openai_config.get('api_key')
    if not api_key:
      api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
      raise Exception("No OpenAI API key found")
    
    log(f"‚úÖ API key found: {api_key[:10]}...")
    
    # Load prompts
    try:
      from docassemble.base.util import path_and_mimetype
      da_path = path_and_mimetype('ai_prompts.json')[0]
      if da_path and os.path.exists(da_path):
        with open(da_path, 'r') as f:
          config = json.load(f)
        log("‚úÖ AI prompts loaded successfully")
      else:
        raise Exception("AI prompts file not found")
    except Exception as e:
      log(f"‚ùå Error loading AI prompts: {e}")
      raise
    
    # Get prompt config
    prompt_config = config['prompts'].get('contradictions_insights')
    if not prompt_config:
      raise ValueError("Contradictions insights prompt not found")
    
    system_prompt = prompt_config.get('system', '')
    user_prompt = prompt_config.get('user_template', '')
    
    # Format user prompt
    try:
      formatted_user_prompt = user_prompt.format(
        formatted_data=formatted_data,
        company_name=user_information.get('company', 'this organization') if defined('user_information') and user_information else 'this organization',
        overall_score=overall_score if defined('overall_score') else 'N/A',
        industry_average=industry_average if defined('industry_average') else 'N/A'
      )
    except KeyError as e:
      log(f"‚ö†Ô∏è Warning: Missing template variable {e}, using raw prompt")
      formatted_user_prompt = user_prompt
    
    # Create OpenAI client
    client = openai.OpenAI(
      api_key=api_key,
      timeout=httpx.Timeout(connect=10.0, write=60.0, read=60.0, pool=30.0),
      max_retries=3
    )
    log("‚úÖ OpenAI client created")
    
    # Make API call
    response = client.chat.completions.create(
      model='gpt-4.1-mini',
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": formatted_user_prompt}
      ],
      max_tokens=1000,
      temperature=0.6
    )
    
    contradictions_insights = response.choices[0].message.content.strip()
    log(f"‚úÖ Contradictions insights generated: {len(contradictions_insights)} chars")
    
  except Exception as e:
    log(f"‚ùå Contradictions insights generation failed: {e}")
    contradictions_insights = f"Contradictions insights generation failed: {str(e)}"

---
# CHUNK 3/4: Challenge Questions Generation
id: generate_challenge_questions
variable: challenge_questions
code: |
  from docassemble.base.util import log, get_config, define
  log("üìã CHUNK 3/4: Challenge Questions Generation - Starting...")
  
  import os
  import json
  import openai
  import httpx
  
  try:
    # Get API key
    api_key = get_config('openai api key')
    if not api_key:
      openai_config = get_config('openai', {})
      api_key = openai_config.get('api_key')
    if not api_key:
      api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
      raise Exception("No OpenAI API key found")
    
    log(f"‚úÖ API key found: {api_key[:10]}...")
    
    # Load prompts
    try:
      from docassemble.base.util import path_and_mimetype
      da_path = path_and_mimetype('ai_prompts.json')[0]
      if da_path and os.path.exists(da_path):
        with open(da_path, 'r') as f:
          config = json.load(f)
        log("‚úÖ AI prompts loaded successfully")
      else:
        raise Exception("AI prompts file not found")
    except Exception as e:
      log(f"‚ùå Error loading AI prompts: {e}")
      raise
    
    # Get prompt config
    prompt_config = config['prompts'].get('challenge_questions')
    if not prompt_config:
      raise ValueError("Challenge questions prompt not found")
    
    system_prompt = prompt_config.get('system', '')
    user_prompt = prompt_config.get('user_template', '')
    
    # Format user prompt
    try:
      formatted_user_prompt = user_prompt.format(
        formatted_data=formatted_data,
        company_name=user_information.get('company', 'this organization') if defined('user_information') and user_information else 'this organization',
        overall_score=overall_score if defined('overall_score') else 'N/A',
        industry_average=industry_average if defined('industry_average') else 'N/A'
      )
    except KeyError as e:
      log(f"‚ö†Ô∏è Warning: Missing template variable {e}, using raw prompt")
      formatted_user_prompt = user_prompt
    
    # Create OpenAI client
    client = openai.OpenAI(
      api_key=api_key,
      timeout=httpx.Timeout(connect=10.0, write=60.0, read=60.0, pool=30.0),
      max_retries=3
    )
    log("‚úÖ OpenAI client created")
    
    # Make API call
    response = client.chat.completions.create(
      model='gpt-4.1-mini',
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": formatted_user_prompt}
      ],
      max_tokens=1000,
      temperature=0.6
    )
    
    challenge_questions = response.choices[0].message.content.strip()
    log(f"‚úÖ Challenge questions generated: {len(challenge_questions)} chars")
    
  except Exception as e:
    log(f"‚ùå Challenge questions generation failed: {e}")
    challenge_questions = f"Challenge questions generation failed: {str(e)}"

---
# CHUNK 4/4: Recommended Services Generation
id: generate_recommended_services
variable: recommended_services
code: |
  from docassemble.base.util import log, get_config, define
  log("üìã CHUNK 4/4: Recommended Services Generation - Starting...")
  
  import os
  import json
  import openai
  import httpx
  
  try:
    # Get API key
    api_key = get_config('openai api key')
    if not api_key:
      openai_config = get_config('openai', {})
      api_key = openai_config.get('api_key')
    if not api_key:
      api_key = os.getenv('OPENAI_API_KEY')
    
    if not api_key:
      raise Exception("No OpenAI API key found")
    
    log(f"‚úÖ API key found: {api_key[:10]}...")
    
    # Load prompts
    try:
      from docassemble.base.util import path_and_mimetype
      da_path = path_and_mimetype('ai_prompts.json')[0]
      if da_path and os.path.exists(da_path):
        with open(da_path, 'r') as f:
          config = json.load(f)
        log("‚úÖ AI prompts loaded successfully")
      else:
        raise Exception("AI prompts file not found")
    except Exception as e:
      log(f"‚ùå Error loading AI prompts: {e}")
      raise
    
    # Get prompt config
    prompt_config = config['prompts'].get('recommended_services')
    if not prompt_config:
      raise ValueError("Recommended services prompt not found")
    
    system_prompt = prompt_config.get('system', '')
    user_prompt = prompt_config.get('user_template', '')
    
    # Format user prompt
    try:
      formatted_user_prompt = user_prompt.format(
        formatted_data=formatted_data,
        company_name=user_information.get('company', 'this organization') if defined('user_information') and user_information else 'this organization',
        overall_score=overall_score if defined('overall_score') else 'N/A',
        industry_average=industry_average if defined('industry_average') else 'N/A'
      )
    except KeyError as e:
      log(f"‚ö†Ô∏è Warning: Missing template variable {e}, using raw prompt")
      formatted_user_prompt = user_prompt
    
    # Create OpenAI client
    client = openai.OpenAI(
      api_key=api_key,
      timeout=httpx.Timeout(connect=10.0, write=60.0, read=60.0, pool=30.0),
      max_retries=3
    )
    log("‚úÖ OpenAI client created")
    
    # Make API call
    response = client.chat.completions.create(
      model='gpt-4.1-mini',
      messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": formatted_user_prompt}
      ],
      max_tokens=1000,
      temperature=0.6
    )
    
    recommended_services = response.choices[0].message.content.strip()
    log(f"‚úÖ Recommended services generated: {len(recommended_services)} chars")
    
  except Exception as e:
    log(f"‚ùå Recommended services generation failed: {e}")
    recommended_services = f"Recommended services generation failed: {str(e)}"
