---
# =============================================================================
# AGENTIC AI ASSESSMENT INTELLIGENCE AGENT
# =============================================================================
# Purpose: Generate dynamic, AI-driven insights using OpenAI API integration
# Input: Current question data, user responses, user context, configuration
# Output: Personalized AI content generated dynamically based on context
# Usage: Provides intelligent, adaptive guidance during assessment
# Dependencies: intelligence_agent_config, questions data, user context, OpenAI API

metadata:
  title: Agentic AI Assessment Intelligence Agent
  description: Dynamic AI-driven insights using OpenAI API for personalized assessment guidance

---
# =============================================================================
# AGENTIC AI CONTENT GENERATOR
# =============================================================================
# Purpose: Generate dynamic, AI-driven insights using OpenAI API integration
# Input: Current question data, user responses, user context, configuration
# Output: Personalized AI content generated dynamically based on context
# Usage: Provides intelligent, adaptive guidance during assessment
# Dependencies: intelligence_agent_config, questions data, user context, OpenAI API

id: generate_intelligence_agent_content
depends on:
  - use_intelligence_agent
  - current_category
  - questions
code: |
  """
  AGENTIC AI ASSESSMENT INTELLIGENCE AGENT

  This block generates dynamic, AI-driven insights using OpenAI API integration.
  It analyzes user responses, provides contextual guidance, and generates
  personalized recommendations based on real-time analysis.

  Agent Capabilities:
  1. Dynamic Content Generation - AI generates contextual explanations
  2. Pattern Analysis - AI analyzes response patterns and trends
  3. Industry-Specific Guidance - AI provides tailored industry insights
  4. Role-Based Recommendations - AI adapts guidance to user's role
  5. Consistency Analysis - AI identifies potential contradictions
  6. Personalized Insights - AI generates unique insights for each user

  The agent uses OpenAI API to generate dynamic content based on:
  - Current question context and category
  - User's industry, role, and company context
  - Previous response patterns and trends
  - Assessment progress and completion status
  """

  # Derive current category locally (no mutation)
  derived_category = ''
  if defined('questions') and defined('current_question') and current_question < len(questions):
    try:
      derived_category = questions[current_question].get('category', '')
    except Exception:
      derived_category = ''
  
  # Check if intelligence agent is enabled
  if not defined('use_intelligence_agent') or not use_intelligence_agent:
    generate_intelligence_agent_content = 'Intelligence agent is disabled.'
  elif not defined('questions') or not defined('current_question') or current_question >= len(questions):
    generate_intelligence_agent_content = 'Loading question data...'
  else:
    current_question_data = questions[current_question]
    
    # Build comprehensive context for AI analysis
    user_context = {
      'industry': user_industry if defined('user_industry') else 'Not specified',
      'role': user_role if defined('user_role') else 'Not specified',
      'company_size': user_company_size if defined('user_company_size') else 'Not specified',
      'current_question': current_question,
      'total_questions': len(questions),
      'current_category': derived_category,
      'question_prompt': current_question_data.get('prompt', ''),
      'progress_percentage': round((current_question / len(questions)) * 100, 1)
    }
    
    # Build response history for pattern analysis
    response_history = []
    if defined('answers') and answers:
      for i in range(min(current_question, len(answers))):
        if answers[i]:
          response_history.append({
            'question_number': i + 1,
            'category': questions[i]['category'],
            'response': answers[i],
            'response_level': 'High' if 'D:' in str(answers[i]) or 'E:' in str(answers[i]) else 'Medium' if 'C:' in str(answers[i]) else 'Low'
          })
    
    # Generate AI prompt for dynamic content generation
    ai_prompt = f"""
    You are an expert business consultant.
    Return a SHORT, high-signal help note (max ~80-120 words), formatted in HTML using <strong> section labels and <br> line breaks.
    Do not repeat the question. Avoid fluff. Focus on CONTEXT and INSIGHT, NOT actionable steps.

    Context:
    - Industry: {user_context['industry']}
    - Role: {user_context['role']}
    - Progress: {user_context['progress_percentage']}% (Q{user_context['current_question'] + 1}/{user_context['total_questions']})
    - Category: {user_context['current_category']}
    - Question: {user_context['question_prompt']}
    - Responses so far: {response_history}

    Guidance for early questions (first 1-2 in a category):
    - Provide orientation: define what "good" looks like in this category for firms like this.
    - Reference typical pitfalls and signals of maturity WITHOUT prescribing steps.
    - Avoid empty progress phrasing; if little data, say "early signals are limited" and ground in category intent.

    Sections to include (only if relevant):
    - Why this matters (1 line)
    - Industry context (1 line)
    - Role perspective (1 line)
    - Assessment insight (1 line) ‚Äî interpret current category intent and what to pay attention to next
    """
    
    # Generate AI content using OpenAI API
    try:
      import openai
      from docassemble.base.util import get_config
      
      # Get OpenAI configuration - using the same pattern as other working files
      api_key = get_config('openai', {}).get('api_key', '')
      
      if not api_key:
        raise Exception("‚ùå AI ERROR: No OpenAI API key configured. Please set up OpenAI API key in Docassemble configuration.")
      
      # Log that we're making API call
      log("ü§ñ Making OpenAI API call to GPT-4.1-mini for intelligence agent")
      
      # Call OpenAI via HTTPS directly to avoid non-pickleable client objects
      try:
        import requests, json
        headers = {
          'Authorization': f'Bearer {api_key}',
          'Content-Type': 'application/json'
        }
        payload = {
          'model': 'gpt-4.1-mini',
          'messages': [
            {'role': 'system', 'content': "You are an expert business consultant providing intelligent, contextual guidance during strategic assessments. Generate dynamic, personalized insights based on the user's specific context and response patterns."},
            {'role': 'user', 'content': ai_prompt}
          ],
          'max_tokens': 800,
          'temperature': 0.7
        }
        resp = requests.post('https://api.openai.com/v1/chat/completions', headers=headers, json=payload, timeout=30)
        resp.raise_for_status()
        data = resp.json()
        ai_content = data['choices'][0]['message']['content']
        # Clean up to avoid storing non-pickleable objects
        del resp
        del data
        
        # Log successful API response
        log("‚úÖ OpenAI API call successful - generating real AI content")
        
        # Format the AI response for display
        generate_intelligence_agent_content = f'<div style="padding-top: 6px;">{ai_content}</div>'
        
      except Exception as api_error:
        log(f"‚ùå OpenAI API call failed: {str(api_error)}")
        raise api_error
      
    except Exception as e:
      # Log the error for debugging
      log(f"‚ùå OpenAI API Error: {str(e)}")
      # Fallback to dynamic content generation if API fails
      # Fallback to dynamic content generation if API fails
      content_sections = []
      
      # Dynamic pattern analysis
      if response_history:
        high_responses = [r for r in response_history if r['response_level'] == 'High']
        low_responses = [r for r in response_history if r['response_level'] == 'Low']
        
        if high_responses:
          high_percentage = (len(high_responses) / len(response_history)) * 100
          if high_percentage >= 60:
            content_sections.append(f"<strong>Performance Analysis:</strong> You're demonstrating strong capabilities in {high_percentage:.0f}% of areas assessed so far, indicating solid organizational foundations.")
          elif high_percentage >= 40:
            content_sections.append(f"<strong>Performance Analysis:</strong> You're showing mixed performance with {high_percentage:.0f}% strong responses, suggesting areas for focused improvement.")
        
        if low_responses:
          low_percentage = (len(low_responses) / len(response_history)) * 100
          if low_percentage >= 40:
            content_sections.append(f"<strong>Growth Opportunity:</strong> {low_percentage:.0f}% of your responses indicate significant improvement potential, representing substantial growth opportunities.")
      
      # Dynamic category analysis
      fallback_category = derived_category
      if fallback_category:
        category_responses = [r for r in response_history if r['category'] == fallback_category]
        if category_responses:
          category_strength = sum(1 for r in category_responses if r['response_level'] == 'High')
          if category_strength == len(category_responses):
            content_sections.append(f"<strong>Category Strength:</strong> You're showing consistent strength in {fallback_category}, indicating this is a well-developed organizational capability.")
          elif category_strength == 0:
            content_sections.append(f"<strong>Focus Area:</strong> {fallback_category} appears to be a key area for development, representing significant growth potential.")
      
      # Dynamic contextual guidance
      if user_context['industry'] != 'Not specified' and derived_category:
        content_sections.append(f"<strong>Industry Context ({user_context['industry']}):</strong> Consider how {derived_category.lower()} impacts your competitive position in the {user_context['industry']} sector.")
      
      if user_context['role'] != 'Not specified' and derived_category:
        content_sections.append(f"<strong>Role Perspective ({user_context['role']}):</strong> Think about how {derived_category.lower()} aligns with your responsibilities and strategic objectives.")
      
      # Dynamic progress insights
      progress = user_context['progress_percentage']
      if progress < 25:
        content_sections.append("<strong>Assessment Context:</strong> You're in the early stages of this assessment. Focus on providing honest, accurate responses to get the most value from the analysis.")
      elif progress < 75:
        content_sections.append("<strong>Assessment Context:</strong> You're making good progress. The patterns in your responses are becoming clearer, providing valuable insights.")
      else:
        content_sections.append("<strong>Assessment Context:</strong> You're nearing completion. The comprehensive analysis will provide detailed insights into your organizational capabilities.")
      
      if content_sections:
        generate_intelligence_agent_content = '<div style="padding-top: 10px;">' + '<br><br>'.join(content_sections) + '</div>'
      else:
        generate_intelligence_agent_content = '<div style="padding-top: 10px;"><strong>Welcome to your assessment!</strong> As you progress through the questions, I\'ll provide dynamic, personalized insights based on your responses and context.</div>'

